{
  "load_data_in_memory": false,
  
  "num_epochs": 25, 
  "num_batches_train": 65, 
  "num_batches_val": 18, 
  "num_batches_test": 8, 
  
  // "job_type": "hyperparams_tuning_e2e",
  // "job_type": "hyperparams_tuning_tl",
  // "job_type": "train_e2e",
  "job_type": "train_tl",

  "hyperparams_tuning_e2e": {},
  "hyperparams_tuning_tl": {
    "local_scale_freeze_first_layers": true,
    "local_scale_freeze_last_layer": true,
    "global_scale_freeze_first_layers": true,
    "global_scale_freeze_last_layer": false,
    
    // FALSE --> when model weights must be initialized with some pre-trained values
    //           BUT we do NOT want to load optimizer, lr scheduler and number 
    //           of epochs.
    //           For example, when training for the very first time a  
    //           transfer learning model
    
    // TRUE  --> when model weights must be initialized with some pre-trained 
    //           values AND we DO want to load optimizer, lr scheduler and 
    //           number of epochs.
    //           For example, when resuming from a previous checkpoint of a  
    //           transfer learning model
    "resume_optim_lr_scheduler_from_checkpoint": false
  },
  "train_e2e": {},
  "train_tl": {
    "local_scale_freeze_first_layers": true,
    "local_scale_freeze_last_layer": false,
    "global_scale_freeze_first_layers": true,
    "global_scale_freeze_last_layer": false,

    // FALSE --> when model weights must be initialized with some pre-trained values
    //           BUT we do NOT want to load optimizer, lr scheduler and number 
    //           of epochs.
    //           For example, when training for the very first time a  
    //           transfer learning model
    
    // TRUE  --> when model weights must be initialized with some pre-trained 
    //           values AND we DO want to load optimizer, lr scheduler and 
    //           number of epochs.
    //           For example, when resuming from a previous checkpoint of a  
    //           transfer learning model
    "resume_optim_lr_scheduler_from_checkpoint": false
  },
  
  "checkpoint_base_path": "../../checkpoints", 
  "checkpoint_step": 25, 
  "checkpoint_to_load_path": "../../checkpoints/2023_02_02_10_11_44/checkpoint_epoch_32_best_val_loss.pth",
  // "checkpoint_to_load_path": null,
  "resume_from_checkpoint_statistics": false,
  
  "learning_rate": 0.00375, 
  "learning_rate_decay_step_size": 5, 
  "learning_rate_decay_factor": 0.9375, 
  
  "momentum": 0.0, 
  
  "disable_wandb": true,
  
  "disable_dashboard": false,
  "terminal_theme": "white",

  // fixed stuff, should be rarely changed

  // "dataset_local_scale_df_path": "../../data/BRATS2013_patches_33_unbalanced/0", 
  // "dataset_global_scale_df_path": "../../data/BRATS2013_patches_65_unbalanced/0", 
  "dataset_local_scale_df_path": "../../data/LiTS17/LITS17_patches_33_unbalanced/0", 
  "dataset_global_scale_df_path": "../../data/LiTS17/LITS17_patches_65_unbalanced/0", 
  "patch_size_local_scale": "33", 
  "patch_size_global_scale": "65", 

  // "local_scale_mean_std_path": "../../data/BRATS2013_patches_33_balanced/0/mean_std.json",
  // "global_scale_mean_std_path": "../../data/BRATS2013_patches_65_balanced/0/mean_std.json",
  "local_scale_mean_std_path": "../../data/LiTS17/LITS17_patches_33_balanced/0/mean_std.json",
  "global_scale_mean_std_path": "../../data/LiTS17/LITS17_patches_65_balanced/0/mean_std.json",

  "batch_size": 64, 
  
  "cascade_type": "input",

  "layers_to_switch": [
    "local_conv_1_maxout_unit_0", "local_conv_1_maxout_unit_1", "concat_conv_0"
  ],

  "layers_to_turn_off": [
    "local_conv_0_maxout_unit_0", 
    "local_conv_0_maxout_unit_1",

    "local_conv_1_maxout_unit_0", 
    "local_conv_1_maxout_unit_1" , 
    
    "global_conv_0_maxout_unit_0", 
    "global_conv_0_maxout_unit_1", 
    "concat_conv_0"
  ],

  "layers_to_copy": [
    "local_conv_1_maxout_unit_0", 
    "local_conv_1_maxout_unit_1",
    "concat_conv_0"
  ],
  "copy_mode": "local_to_global",
  
  "delta_1": 0.0, 
  "delta_2": 0.0, 

  "dropout": 0.0, 
  "standardize": true,

  "optimizer_name": "SGD",

  "num_classes": 6,



  "test_key": null
}
